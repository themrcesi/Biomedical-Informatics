{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#File-paths\" data-toc-modified-id=\"File-paths-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>File paths</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creación-del-Diccionario\" data-toc-modified-id=\"Creación-del-Diccionario-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Creación del Diccionario</a></span></li><li><span><a href=\"#BOW-generation\" data-toc-modified-id=\"BOW-generation-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>BOW generation</a></span></li><li><span><a href=\"#Similarity-matrix-generation\" data-toc-modified-id=\"Similarity-matrix-generation-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Similarity matrix generation</a></span></li></ul></li><li><span><a href=\"#Data-load\" data-toc-modified-id=\"Data-load-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data load</a></span><ul class=\"toc-item\"><li><span><a href=\"#Titles\" data-toc-modified-id=\"Titles-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Titles</a></span></li><li><span><a href=\"#Judgements\" data-toc-modified-id=\"Judgements-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Judgements</a></span></li><li><span><a href=\"#Queries\" data-toc-modified-id=\"Queries-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Queries</a></span></li><li><span><a href=\"#Metadata\" data-toc-modified-id=\"Metadata-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Metadata</a></span></li></ul></li><li><span><a href=\"#Retrieval-models\" data-toc-modified-id=\"Retrieval-models-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Retrieval models</a></span><ul class=\"toc-item\"><li><span><a href=\"#TFIDF-Model\" data-toc-modified-id=\"TFIDF-Model-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>TFIDF Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-of-evaluation\" data-toc-modified-id=\"Example-of-evaluation-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Example of evaluation</a></span></li><li><span><a href=\"#Parameterized-Evaluation\" data-toc-modified-id=\"Parameterized-Evaluation-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Parameterized Evaluation</a></span></li></ul></li><li><span><a href=\"#TFIDF-2.0\" data-toc-modified-id=\"TFIDF-2.0-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>TFIDF 2.0</a></span></li><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Word2Vec</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creation\" data-toc-modified-id=\"Creation-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Creation</a></span></li><li><span><a href=\"#Saving\" data-toc-modified-id=\"Saving-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Saving</a></span></li><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>Loading</a></span></li><li><span><a href=\"#Getting-embedding\" data-toc-modified-id=\"Getting-embedding-6.3.4\"><span class=\"toc-item-num\">6.3.4&nbsp;&nbsp;</span>Getting embedding</a></span></li><li><span><a href=\"#Queries-embeddings\" data-toc-modified-id=\"Queries-embeddings-6.3.5\"><span class=\"toc-item-num\">6.3.5&nbsp;&nbsp;</span>Queries embeddings</a></span></li><li><span><a href=\"#Documents-embeddings\" data-toc-modified-id=\"Documents-embeddings-6.3.6\"><span class=\"toc-item-num\">6.3.6&nbsp;&nbsp;</span>Documents embeddings</a></span></li><li><span><a href=\"#Launch-query-in-W2V-Model\" data-toc-modified-id=\"Launch-query-in-W2V-Model-6.3.7\"><span class=\"toc-item-num\">6.3.7&nbsp;&nbsp;</span>Launch query in W2V Model</a></span></li></ul></li><li><span><a href=\"#Latent-Semantic-Indexing\" data-toc-modified-id=\"Latent-Semantic-Indexing-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Latent Semantic Indexing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-creation\" data-toc-modified-id=\"Model-creation-6.4.1\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>Model creation</a></span></li><li><span><a href=\"#Similarities-matrix\" data-toc-modified-id=\"Similarities-matrix-6.4.2\"><span class=\"toc-item-num\">6.4.2&nbsp;&nbsp;</span>Similarities matrix</a></span></li><li><span><a href=\"#Launching-queries\" data-toc-modified-id=\"Launching-queries-6.4.3\"><span class=\"toc-item-num\">6.4.3&nbsp;&nbsp;</span>Launching queries</a></span></li></ul></li></ul></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Results</a></span></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Conclusions</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "Make sure you have downloaded the following pakcages in your environment:\n",
    "\n",
    "- nltk: nltk.download('stopwords')\n",
    "- xmltodict\n",
    "- numpy\n",
    "- gensim\n",
    "- pandas\n",
    "- matplotlib\n",
    "- dask\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Import the required libraries for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T10:23:08.031132Z",
     "start_time": "2020-12-13T10:23:08.028131Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import xmltodict as xtd\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from joblib import Parallel, delayed\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import pandas as pd\n",
    "from gensim.similarities import MatrixSimilarity, SparseMatrixSimilarity, Similarity\n",
    "from operator import itemgetter\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File paths\n",
    "\n",
    "Add the paths for the queries file, the texts (documents) and the judements file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T08:52:21.213020Z",
     "start_time": "2020-12-13T08:52:21.172022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npath_queries = r\"C:/Users/David.Rubio/Desktop/muia/topics-rnd5.xml\"\\npath_texts = \"C:/Users/David.Rubio/Desktop/muia/2020-07-16/document_parses/pdf_json\"\\npath_judgements = \"C:/Users/David.Rubio/Desktop/muia/qrels-covid_d5_j0.5-5.txt\"\\npath_judgements2 = \"C:/Users/David.Rubio/Desktop/muia/qrels-covid_d5_j0.5-5.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_queries = r\"B:\\document_parser\\document_parses\\topics-rnd5.xml\"\n",
    "path_texts = \"B:\\document_parser\\document_parses\\pdf_json\"\n",
    "path_test = \"B:/document_parser/document_parses/test\"\n",
    "path_judgements = \"B:/document_parser/document_parses/judgements.csv\"\n",
    "path_judgements2 = \"B:/document_parser/document_parses/judgements2.csv\"\n",
    "\"\"\"\n",
    "path_queries = r\"C:/Users/David.Rubio/Desktop/muia/topics-rnd5.xml\"\n",
    "path_texts = \"C:/Users/David.Rubio/Desktop/muia/2020-07-16/document_parses/pdf_json\"\n",
    "path_judgements = \"C:/Users/David.Rubio/Desktop/muia/qrels-covid_d5_j0.5-5.txt\"\n",
    "path_judgements2 = \"C:/Users/David.Rubio/Desktop/muia/qrels-covid_d5_j0.5-5.txt\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this section, the dictionary, the bag of words (bow) and the similarity matrix will be generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del Diccionario\n",
    "\n",
    "Regarding the dictionary, we found out that there exists another special dictionary called HashDictionary, that doesn´t need to be filled before used it. However, it is likely that two different words get the same key. So, we decided to use the basic one in spite of having to fill it before hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:10:39.107246Z",
     "start_time": "2020-12-13T09:07:58.835131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1392828 unique tokens: ['abl', 'absenc', 'absent', 'abundantli', 'accept']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(line.split() for line in open(\"docs.txt\",\"r\"))\n",
    "dictionary.save('covid19.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW generation\n",
    "\n",
    "First, the stopwords list needs to be assigned to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:10:39.158247Z",
     "start_time": "2020-12-13T09:10:39.155247Z"
    }
   },
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method *preprocess_document* processes a document given a stopword list. In this method, we concatenate the information given by the title, the abstract and the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:10:39.214247Z",
     "start_time": "2020-12-13T09:10:39.208246Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_document(doc,stopset):\n",
    "    title = np.array([doc[\"metadata\"][\"title\"]], dtype=str)\n",
    "    abstract = np.array([paragraph[\"text\"] for paragraph in doc[\"abstract\"]], dtype=str)\n",
    "    text = np.array([paragraph[\"text\"] for paragraph in doc[\"body_text\"]], dtype=str)\n",
    "    stemmer = PorterStemmer()\n",
    "    information = np.concatenate((title, abstract, text))\n",
    "    tokens = np.concatenate(([wordpunct_tokenize(inf) for inf in information]))\n",
    "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2 and not token.isnumeric()]\n",
    "    final = \" \".join([stemmer.stem(word) for word in clean])\n",
    "    return title[0], str(final.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data each file in path_texts we write one row per document in docs.txt with the most relevant information (use preprocess_document). This information will be essential to build the dictionary. This step takes more than an hour so, unless you need to generate the file, we strongly suggest not to remove the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T10:54:03.397173Z",
     "start_time": "2020-12-05T10:54:03.394172Z"
    }
   },
   "outputs": [],
   "source": [
    "#files = glob.glob(path_texts + \"/*.json\")\n",
    "#with open(\"docs.txt\", \"w+\") as f:\n",
    "#    i = 1\n",
    " #   for file in files:\n",
    "  #      print(i)\n",
    "   #     i+=1\n",
    "    #    with open(file) as js:\n",
    "     #       file_json = json.load(js)\n",
    "      #  _, stems = preprocess_document(file_json, stopset)\n",
    "       # f.write(stems.strip('b\\'')+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class MyCorpus will help to iterate (\\_\\_iter\\_\\_ method) over each line of a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:10:39.265248Z",
     "start_time": "2020-12-13T09:10:39.262248Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \n",
    "    def __init__(self, file):\n",
    "        self.path = file\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in open(self.path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield dictionary.doc2bow(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over each row in \"docs.txt\" to build the bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:13:25.307108Z",
     "start_time": "2020-12-13T09:10:39.316280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x0000021E22023D48>\n"
     ]
    }
   ],
   "source": [
    "path_corpus = \"docs.txt\"\n",
    "bow = MyCorpus(path_corpus)\n",
    "corpora.MmCorpus.serialize(\"covid19.mm\", bow, metadata=True)\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity matrix generation\n",
    "\n",
    "Regarding the similarities, we chose to use Similarity instead of MatrixSimilarity since it allows lazy generation, not making us to store all the data in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:22:42.497388Z",
     "start_time": "2020-12-13T09:18:37.290958Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "index_temp = get_tmpfile(\"index\")\n",
    "index = Similarity(None, corpus = bow, num_features=len(dictionary))  # create index\n",
    "index.save(\"covid19.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load \n",
    "\n",
    "In this section, relevant information will be loaded locally (title, judgmenets...). This information is useful during the evaluation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titles\n",
    "\n",
    "The title and the paper_id for each document in \"path_texts\" are needed to link the paper_id retrieved by the model with the title.\n",
    "\n",
    "For this task, dask is used to reduce the computing time (parallel computing): 6 workers with 2 threads per worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:23:07.998950Z",
     "start_time": "2020-12-13T09:23:07.101948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Anaconda3\\lib\\site-packages\\distributed\\dashboard\\core.py:79: UserWarning: \n",
      "Failed to start diagnostics server on port 8787. [WinError 10048] Solo se permite un uso de cada dirección de socket (protocolo/dirección de red/puerto)\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:50738</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:50741/status' target='_blank'>http://127.0.0.1:50741/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>34.31 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:50738' processes=6 threads=12, memory=34.31 GB>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.bag as db\n",
    "from dask.distributed import Client, progress\n",
    "client = Client(n_workers=6, threads_per_worker=2)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method load_dataset calls load_json for each file in the path. For this document, load_json calls load_dataset to get the paper_id, the title, the abtract and the body of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.637557Z",
     "start_time": "2020-12-13T09:08:15.155Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    files = glob.glob(path + \"/*.json\")\n",
    "    b = db.from_sequence(files).map(load_json)\n",
    "    df = b.to_dataframe(columns=[\"id\", \"title\", \"abstract\", \"body\"])\n",
    "    return df\n",
    "\n",
    "def load_document(doc):\n",
    "    title = doc[\"metadata\"][\"title\"]\n",
    "    abstract = \" \".join([paragraph[\"text\"] for paragraph in doc[\"abstract\"]])\n",
    "    text = \" \".join([paragraph[\"text\"] for paragraph in doc[\"body_text\"]])\n",
    "    returned = {}\n",
    "    returned[\"id\"] = doc[\"paper_id\"]\n",
    "    returned[\"title\"] = title\n",
    "    returned[\"abstract\"] = abstract\n",
    "    returned[\"body\"] = text\n",
    "    return returned\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path) as file:\n",
    "        file_json = json.load(file)\n",
    "    returned = load_document(file_json)\n",
    "    return returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is built (dataframe with paper_id, title, abstract and body columns for each document in \"path_texts\"). Then, the relevant parts of each row are selected (id and title)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.639557Z",
     "start_time": "2020-12-13T09:08:17.357Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(path_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.641559Z",
     "start_time": "2020-12-13T09:08:17.804Z"
    }
   },
   "outputs": [],
   "source": [
    "titles = dataset[[\"id\",\"title\"]].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.643555Z",
     "start_time": "2020-12-13T09:08:18.252Z"
    }
   },
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Judgements\n",
    "\n",
    "The next file needed for the evaluation is the judgements. This file contains for each query a set of cord_uid (unique identifiers for each paper) and, linked with each pair, the score (relevance). The score can be 0,1 or 2 so, the first step is to binarize it (1 if the score is greater or equal to 1, and 0 otherwise). The documents selected for each query comes from the suggestions given by different search engines. With these documents, a \"pool\" is generated and experts analyze if the documents in the pool are relevant for the query or not. The content of judgements will be the key to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.646557Z",
     "start_time": "2020-12-13T09:08:20.252Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_judgements(path_judgements):\n",
    "    judgements = pd.read_csv(path_judgements, delimiter=' ', names = [\"query\", \"cord_uid\", \"score\"], usecols=[0,2,3])\n",
    "    judgements.loc[judgements['score'] < 1, 'binary_score'] = 0\n",
    "    judgements.loc[judgements['score'] >=1 , 'binary_score'] = 1\n",
    "    return judgements\n",
    "\n",
    "judgements = load_judgements(path_judgements2)\n",
    "judgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries\n",
    "\n",
    "The content of the file help to link the number of the query in the judgements file with the text of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.648557Z",
     "start_time": "2020-12-13T09:08:21.014Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_queries(queries_path):\n",
    "    \"\"\"\n",
    "    Receives the path of the queries files and returns a dictionary containing all the queries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    queries_path : path of the queries file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dic_judgements : dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    with open(queries_path, \"r\") as xml_file:\n",
    "        data_dict = xtd.parse(xml_file.read())\n",
    "    xml_file.close()\n",
    "\n",
    "    dic_queries = {}\n",
    "    for query in data_dict[\"topics\"][\"topic\"]:\n",
    "        dic_queries[query[\"@number\"]] = query[\"query\"]\n",
    "\n",
    "    df = pd.DataFrame.from_dict(dic_queries, orient='index', columns=['query'])\n",
    "\n",
    "    return df\n",
    "\n",
    "queries = load_queries(path_queries)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata file link the identifier of the paper used for indexing the documents with the cord_uid given in the judgements file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.649556Z",
     "start_time": "2020-12-13T09:08:22.748Z"
    }
   },
   "outputs": [],
   "source": [
    "path_metadata = \"B:/document_parser/document_parses/metadata.csv\"\n",
    "#path_metadata = \"C:/Users/David.Rubio/Desktop/muia/2020-07-16/metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.651556Z",
     "start_time": "2020-12-13T09:08:23.652Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(path_metadata, header = 0, usecols = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.825586Z",
     "start_time": "2020-12-13T09:08:24.189Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = metadata.assign(sha=metadata.sha.str.split('; ')).explode('sha')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.827588Z",
     "start_time": "2020-12-13T09:08:24.636Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata['sha'].isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.830589Z",
     "start_time": "2020-12-13T09:08:25.228Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = metadata.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Model\n",
    "\n",
    "The TFIDF (Term Frequency Inversed Document Frequency) model is a numerical statistical model. This model returns a score which indicates how important is a word/query for a document in a corpus (collection). This score is proportional to the number of times the word(s) appears (tf) and inversly proportional to the number of documents that contains this word(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we need to do is loading the bag of words created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.832589Z",
     "start_time": "2020-12-13T09:08:27.932Z"
    }
   },
   "outputs": [],
   "source": [
    "bow = corpora.MmCorpus('covid19.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we also load the dictionary and the similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.834587Z",
     "start_time": "2020-12-13T09:08:29.829Z"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(\"covid19.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:23:33.728889Z",
     "start_time": "2020-12-13T09:23:33.720890Z"
    }
   },
   "outputs": [],
   "source": [
    "similarities = Similarity.load(\"covid19.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we loaded the bow, dictionary and similarities, we are able to create our TFIDF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.838587Z",
     "start_time": "2020-12-13T09:08:31.893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default model uses nfc from SMART notation.\n",
    "model_tfidf = models.TfidfModel(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to execute a query that returns the ranking of documents retrieved for that specific query. Moreover, a util function to preprocess the query is created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:14:59.840587Z",
     "start_time": "2020-12-13T09:08:33.086Z"
    }
   },
   "outputs": [],
   "source": [
    "def launch_query_tfidf(model, dictionary, bow, index, query, titles, verbose = 0):\n",
    "    \"\"\"\n",
    "    Given a specific query, it returns the ranking of documents.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : tfidf model\n",
    "    dictionary: dictionary created\n",
    "    bow: bag of words\n",
    "    index: similarities matrix\n",
    "    query: specific query\n",
    "    titles: dataframe of the titles\n",
    "    verbose: flag for printing messages\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ranking: ranking for the query in this format: [(doc_position, score), (doc_position, score), ... ]\n",
    "    similarities: similarities matrix\n",
    "\n",
    "    \"\"\"\n",
    "    stopset = set(stopwords.words(\"english\"))\n",
    "    index = index\n",
    "    pq = preprocess_query_tfidf(query, stopset)\n",
    "    vq = dictionary.doc2bow(pq)\n",
    "    qtfidf = model[vq]\n",
    "    sim = index[qtfidf]\n",
    "    ranking = sorted(enumerate(sim), key=itemgetter(1), reverse=True)\n",
    "    if verbose:\n",
    "        print(\"Query ==> \"+query)\n",
    "        for doc, score in ranking[:5]:\n",
    "            print(\"[ Score = \" + \"%.3f\" % round(score,3) + \" ] \" + titles['title'].iloc[doc])\n",
    "    return ranking, sim\n",
    "        \n",
    "def preprocess_query_tfidf(query, stopset):\n",
    "    \"\"\"\n",
    "    Basic function that preprocess a query given a stopset: tokenization, lower case, stopwords removal and stemming.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query: query to preprocess\n",
    "    stopset: set containing stopwords\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    stems: stems of the given query\n",
    "    \n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = wordpunct_tokenize(query)\n",
    "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\n",
    "    stems = [stemmer.stem(word) for word in clean]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We execute it to show you how it works. (Notice that in this case verbose is marked as 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:23:37.865709Z",
     "start_time": "2020-12-13T09:23:37.577464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ==> coronavirus response to weather changes\n",
      "[ Score = 0.421 ] Advice-giving in newspaper weather commentaries\n",
      "[ Score = 0.387 ] Severe weather warnings predict fracture epidemics\n",
      "[ Score = 0.348 ] The Weather Impacts the Outbreak of COVID-19 in Mainland China\n",
      "[ Score = 0.324 ] Comparison of culturable antibiotic-resistant bacteria in polluted and non- polluted air in Beijing, China\n",
      "[ Score = 0.292 ] Weather-Dependent Risk for Legionnaires' Disease, United States Legionella pneumophila [leʺjə-nelʹə nooʺmo-filʹə]\n"
     ]
    }
   ],
   "source": [
    "ranking, sim = launch_query_tfidf(model_tfidf, dictionary, bow, similarities, queries.iloc[1][0], titles, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of evaluation\n",
    "\n",
    "Once we are able to launch queries, it´s time for evaluation. We are going to show you step by step the process of evaluation for the query launched before. Once this process is explained, we will create parameterized functions in order to improve the quality and organization of our code, making us able to reuse it later.\n",
    "\n",
    "The first thing that we do is creating a dataframe from the ranking obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:14.845414Z",
     "start_time": "2020-12-13T09:24:14.637897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_position</th>\n",
       "      <th>rel_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54321</td>\n",
       "      <td>0.420703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12462</td>\n",
       "      <td>0.387222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11917</td>\n",
       "      <td>0.348274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83769</td>\n",
       "      <td>0.323658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41404</td>\n",
       "      <td>0.292001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84415</th>\n",
       "      <td>84377</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84416</th>\n",
       "      <td>84391</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84417</th>\n",
       "      <td>84397</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84418</th>\n",
       "      <td>84407</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84419</th>\n",
       "      <td>84408</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84420 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_position  rel_score\n",
       "0             54321   0.420703\n",
       "1             12462   0.387222\n",
       "2             11917   0.348274\n",
       "3             83769   0.323658\n",
       "4             41404   0.292001\n",
       "...             ...        ...\n",
       "84415         84377   0.000000\n",
       "84416         84391   0.000000\n",
       "84417         84397   0.000000\n",
       "84418         84407   0.000000\n",
       "84419         84408   0.000000\n",
       "\n",
       "[84420 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking = [[position[0], position[1]] for position in ranking]\n",
    "ranking = pd.DataFrame(ranking, columns=[\"doc_position\", \"rel_score\"])\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we include the sha identifier of each document result and its global ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:16.449693Z",
     "start_time": "2020-12-13T09:24:15.821666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_position</th>\n",
       "      <th>rel_score</th>\n",
       "      <th>sha</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54321</td>\n",
       "      <td>0.420703</td>\n",
       "      <td>a4b6c8a9ecb94ba17e416cff443028d996454039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12462</td>\n",
       "      <td>0.387222</td>\n",
       "      <td>25f4d6c2f2dcb5f46464f5a31603be4606cb7116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11917</td>\n",
       "      <td>0.348274</td>\n",
       "      <td>244c5c9c6a6fb239d47c9b0016c62d24c23bf3e8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83769</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>fdebb2b0f78abab06a7b1843831fdaa78c3463f7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41404</td>\n",
       "      <td>0.292001</td>\n",
       "      <td>7d7255ec9a213b7fe04cb8c08b326e0aacd2fd9b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84415</th>\n",
       "      <td>84377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ffe3b2ad5b565d38aebab45629d4329fe8bf4e02</td>\n",
       "      <td>84415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84416</th>\n",
       "      <td>84391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ffea289feac032cd0ba2c8890a9a725c763af652</td>\n",
       "      <td>84416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84417</th>\n",
       "      <td>84397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ffed5d2a31a0c1a0db11905fe378e7735b6d70ca</td>\n",
       "      <td>84417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84418</th>\n",
       "      <td>84407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>fff3678cfe3ce7a9ccae1e7becf17d5d71d1b54a</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84419</th>\n",
       "      <td>84408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>fff37ff9de7ac14189bacc386448ae96a624f19f</td>\n",
       "      <td>84419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84420 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_position  rel_score                                       sha  \\\n",
       "0             54321   0.420703  a4b6c8a9ecb94ba17e416cff443028d996454039   \n",
       "1             12462   0.387222  25f4d6c2f2dcb5f46464f5a31603be4606cb7116   \n",
       "2             11917   0.348274  244c5c9c6a6fb239d47c9b0016c62d24c23bf3e8   \n",
       "3             83769   0.323658  fdebb2b0f78abab06a7b1843831fdaa78c3463f7   \n",
       "4             41404   0.292001  7d7255ec9a213b7fe04cb8c08b326e0aacd2fd9b   \n",
       "...             ...        ...                                       ...   \n",
       "84415         84377   0.000000  ffe3b2ad5b565d38aebab45629d4329fe8bf4e02   \n",
       "84416         84391   0.000000  ffea289feac032cd0ba2c8890a9a725c763af652   \n",
       "84417         84397   0.000000  ffed5d2a31a0c1a0db11905fe378e7735b6d70ca   \n",
       "84418         84407   0.000000  fff3678cfe3ce7a9ccae1e7becf17d5d71d1b54a   \n",
       "84419         84408   0.000000  fff37ff9de7ac14189bacc386448ae96a624f19f   \n",
       "\n",
       "       ranking  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  \n",
       "3            3  \n",
       "4            4  \n",
       "...        ...  \n",
       "84415    84415  \n",
       "84416    84416  \n",
       "84417    84417  \n",
       "84418    84418  \n",
       "84419    84419  \n",
       "\n",
       "[84420 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ranking\n",
    "results[\"sha\"] = results[\"doc_position\"].map(lambda x: titles[\"id\"].iloc[x])\n",
    "results[\"ranking\"] = results.index\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we join this dataframe with metadata in order to obtain the cord_uid of each document retrieved. This will allow us later to obtain the relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:17.546371Z",
     "start_time": "2020-12-13T09:24:17.197411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_position</th>\n",
       "      <th>rel_score</th>\n",
       "      <th>ranking</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a4b6c8a9ecb94ba17e416cff443028d996454039</th>\n",
       "      <td>54321</td>\n",
       "      <td>0.420703</td>\n",
       "      <td>0</td>\n",
       "      <td>kftchnhz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25f4d6c2f2dcb5f46464f5a31603be4606cb7116</th>\n",
       "      <td>12462</td>\n",
       "      <td>0.387222</td>\n",
       "      <td>1</td>\n",
       "      <td>2p9j4ksy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244c5c9c6a6fb239d47c9b0016c62d24c23bf3e8</th>\n",
       "      <td>11917</td>\n",
       "      <td>0.348274</td>\n",
       "      <td>2</td>\n",
       "      <td>akb96git</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdebb2b0f78abab06a7b1843831fdaa78c3463f7</th>\n",
       "      <td>83769</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>3</td>\n",
       "      <td>h5ufxzv9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d7255ec9a213b7fe04cb8c08b326e0aacd2fd9b</th>\n",
       "      <td>41404</td>\n",
       "      <td>0.292001</td>\n",
       "      <td>4</td>\n",
       "      <td>lv8dvdp7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe3b2ad5b565d38aebab45629d4329fe8bf4e02</th>\n",
       "      <td>84377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84415</td>\n",
       "      <td>wg1qwmj1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffea289feac032cd0ba2c8890a9a725c763af652</th>\n",
       "      <td>84391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84416</td>\n",
       "      <td>alsps70x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffed5d2a31a0c1a0db11905fe378e7735b6d70ca</th>\n",
       "      <td>84397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84417</td>\n",
       "      <td>dabu4ohl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff3678cfe3ce7a9ccae1e7becf17d5d71d1b54a</th>\n",
       "      <td>84407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84418</td>\n",
       "      <td>1qtqergw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff37ff9de7ac14189bacc386448ae96a624f19f</th>\n",
       "      <td>84408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84419</td>\n",
       "      <td>prqrvemt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84425 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          doc_position  rel_score  ranking  \\\n",
       "sha                                                                          \n",
       "a4b6c8a9ecb94ba17e416cff443028d996454039         54321   0.420703        0   \n",
       "25f4d6c2f2dcb5f46464f5a31603be4606cb7116         12462   0.387222        1   \n",
       "244c5c9c6a6fb239d47c9b0016c62d24c23bf3e8         11917   0.348274        2   \n",
       "fdebb2b0f78abab06a7b1843831fdaa78c3463f7         83769   0.323658        3   \n",
       "7d7255ec9a213b7fe04cb8c08b326e0aacd2fd9b         41404   0.292001        4   \n",
       "...                                                ...        ...      ...   \n",
       "ffe3b2ad5b565d38aebab45629d4329fe8bf4e02         84377   0.000000    84415   \n",
       "ffea289feac032cd0ba2c8890a9a725c763af652         84391   0.000000    84416   \n",
       "ffed5d2a31a0c1a0db11905fe378e7735b6d70ca         84397   0.000000    84417   \n",
       "fff3678cfe3ce7a9ccae1e7becf17d5d71d1b54a         84407   0.000000    84418   \n",
       "fff37ff9de7ac14189bacc386448ae96a624f19f         84408   0.000000    84419   \n",
       "\n",
       "                                          cord_uid  \n",
       "sha                                                 \n",
       "a4b6c8a9ecb94ba17e416cff443028d996454039  kftchnhz  \n",
       "25f4d6c2f2dcb5f46464f5a31603be4606cb7116  2p9j4ksy  \n",
       "244c5c9c6a6fb239d47c9b0016c62d24c23bf3e8  akb96git  \n",
       "fdebb2b0f78abab06a7b1843831fdaa78c3463f7  h5ufxzv9  \n",
       "7d7255ec9a213b7fe04cb8c08b326e0aacd2fd9b  lv8dvdp7  \n",
       "...                                            ...  \n",
       "ffe3b2ad5b565d38aebab45629d4329fe8bf4e02  wg1qwmj1  \n",
       "ffea289feac032cd0ba2c8890a9a725c763af652  alsps70x  \n",
       "ffed5d2a31a0c1a0db11905fe378e7735b6d70ca  dabu4ohl  \n",
       "fff3678cfe3ce7a9ccae1e7becf17d5d71d1b54a  1qtqergw  \n",
       "fff37ff9de7ac14189bacc386448ae96a624f19f  prqrvemt  \n",
       "\n",
       "[84425 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.set_index(\"sha\").join(metadata.set_index(\"sha\"))\n",
    "results = results.sort_values(by=[\"ranking\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that there are some null values in the cord_uid column. This means that some documents of our corpus don´t have a cord_uid in the metadata, so we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:18.937762Z",
     "start_time": "2020-12-13T09:24:18.926766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['cord_uid'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:19.462848Z",
     "start_time": "2020-12-13T09:24:19.437850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_position</th>\n",
       "      <th>rel_score</th>\n",
       "      <th>ranking</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a4b6c8a9ecb94ba17e416cff443028d996454039</th>\n",
       "      <td>54321</td>\n",
       "      <td>0.420703</td>\n",
       "      <td>0</td>\n",
       "      <td>kftchnhz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25f4d6c2f2dcb5f46464f5a31603be4606cb7116</th>\n",
       "      <td>12462</td>\n",
       "      <td>0.387222</td>\n",
       "      <td>1</td>\n",
       "      <td>2p9j4ksy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244c5c9c6a6fb239d47c9b0016c62d24c23bf3e8</th>\n",
       "      <td>11917</td>\n",
       "      <td>0.348274</td>\n",
       "      <td>2</td>\n",
       "      <td>akb96git</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdebb2b0f78abab06a7b1843831fdaa78c3463f7</th>\n",
       "      <td>83769</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>3</td>\n",
       "      <td>h5ufxzv9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d7255ec9a213b7fe04cb8c08b326e0aacd2fd9b</th>\n",
       "      <td>41404</td>\n",
       "      <td>0.292001</td>\n",
       "      <td>4</td>\n",
       "      <td>lv8dvdp7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe3b2ad5b565d38aebab45629d4329fe8bf4e02</th>\n",
       "      <td>84377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84415</td>\n",
       "      <td>wg1qwmj1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffea289feac032cd0ba2c8890a9a725c763af652</th>\n",
       "      <td>84391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84416</td>\n",
       "      <td>alsps70x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffed5d2a31a0c1a0db11905fe378e7735b6d70ca</th>\n",
       "      <td>84397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84417</td>\n",
       "      <td>dabu4ohl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff3678cfe3ce7a9ccae1e7becf17d5d71d1b54a</th>\n",
       "      <td>84407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84418</td>\n",
       "      <td>1qtqergw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff37ff9de7ac14189bacc386448ae96a624f19f</th>\n",
       "      <td>84408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84419</td>\n",
       "      <td>prqrvemt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          doc_position  rel_score  ranking  \\\n",
       "sha                                                                          \n",
       "a4b6c8a9ecb94ba17e416cff443028d996454039         54321   0.420703        0   \n",
       "25f4d6c2f2dcb5f46464f5a31603be4606cb7116         12462   0.387222        1   \n",
       "244c5c9c6a6fb239d47c9b0016c62d24c23bf3e8         11917   0.348274        2   \n",
       "fdebb2b0f78abab06a7b1843831fdaa78c3463f7         83769   0.323658        3   \n",
       "7d7255ec9a213b7fe04cb8c08b326e0aacd2fd9b         41404   0.292001        4   \n",
       "...                                                ...        ...      ...   \n",
       "ffe3b2ad5b565d38aebab45629d4329fe8bf4e02         84377   0.000000    84415   \n",
       "ffea289feac032cd0ba2c8890a9a725c763af652         84391   0.000000    84416   \n",
       "ffed5d2a31a0c1a0db11905fe378e7735b6d70ca         84397   0.000000    84417   \n",
       "fff3678cfe3ce7a9ccae1e7becf17d5d71d1b54a         84407   0.000000    84418   \n",
       "fff37ff9de7ac14189bacc386448ae96a624f19f         84408   0.000000    84419   \n",
       "\n",
       "                                          cord_uid  \n",
       "sha                                                 \n",
       "a4b6c8a9ecb94ba17e416cff443028d996454039  kftchnhz  \n",
       "25f4d6c2f2dcb5f46464f5a31603be4606cb7116  2p9j4ksy  \n",
       "244c5c9c6a6fb239d47c9b0016c62d24c23bf3e8  akb96git  \n",
       "fdebb2b0f78abab06a7b1843831fdaa78c3463f7  h5ufxzv9  \n",
       "7d7255ec9a213b7fe04cb8c08b326e0aacd2fd9b  lv8dvdp7  \n",
       "...                                            ...  \n",
       "ffe3b2ad5b565d38aebab45629d4329fe8bf4e02  wg1qwmj1  \n",
       "ffea289feac032cd0ba2c8890a9a725c763af652  alsps70x  \n",
       "ffed5d2a31a0c1a0db11905fe378e7735b6d70ca  dabu4ohl  \n",
       "fff3678cfe3ce7a9ccae1e7becf17d5d71d1b54a  1qtqergw  \n",
       "fff37ff9de7ac14189bacc386448ae96a624f19f  prqrvemt  \n",
       "\n",
       "[83585 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.dropna()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we launched query 2, so now we need to obtain the relevance judgements of query 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:20.911377Z",
     "start_time": "2020-12-13T09:24:20.901377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>score</th>\n",
       "      <th>binary_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>2</td>\n",
       "      <td>01goni72</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>2</td>\n",
       "      <td>01yc7lzk</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>2</td>\n",
       "      <td>02cy1s8x</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>2</td>\n",
       "      <td>02f0opkr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>2</td>\n",
       "      <td>03h85lvy</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>2</td>\n",
       "      <td>zw0xh341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>2</td>\n",
       "      <td>zx28gr34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>2</td>\n",
       "      <td>zxvim4t8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>2</td>\n",
       "      <td>zxx7tikz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>2</td>\n",
       "      <td>zytu7wue</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1287 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query  cord_uid  score  binary_score\n",
       "1647      2  01goni72      2           1.0\n",
       "1648      2  01yc7lzk      0           0.0\n",
       "1649      2  02cy1s8x      0           0.0\n",
       "1650      2  02f0opkr      0           0.0\n",
       "1651      2  03h85lvy      2           1.0\n",
       "...     ...       ...    ...           ...\n",
       "2929      2  zw0xh341      0           0.0\n",
       "2930      2  zx28gr34      0           0.0\n",
       "2931      2  zxvim4t8      0           0.0\n",
       "2932      2  zxx7tikz      2           1.0\n",
       "2933      2  zytu7wue      0           0.0\n",
       "\n",
       "[1287 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgements_parcial = judgements[judgements[\"query\"] == 2]\n",
    "judgements_parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the judgements of query 2, we join this judgements with our ranking. This operation will allow us to know for each document retrieved whether it was relevant or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:22.776298Z",
     "start_time": "2020-12-13T09:24:22.615300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_position</th>\n",
       "      <th>rel_score</th>\n",
       "      <th>ranking</th>\n",
       "      <th>query</th>\n",
       "      <th>score</th>\n",
       "      <th>binary_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cord_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000ajevz</th>\n",
       "      <td>7623</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>52295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000q5l5n</th>\n",
       "      <td>17269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000tfenb</th>\n",
       "      <td>66091</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>38919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001u8ecb</th>\n",
       "      <td>6127</td>\n",
       "      <td>0.026825</td>\n",
       "      <td>3817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003r4sjl</th>\n",
       "      <td>24650</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>60799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzvmj5qy</th>\n",
       "      <td>16372</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>40313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzw7zlh6</th>\n",
       "      <td>12233</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>74181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzxjv666</th>\n",
       "      <td>57978</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>22277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzykyblm</th>\n",
       "      <td>75960</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>34410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzys31e9</th>\n",
       "      <td>38250</td>\n",
       "      <td>0.023491</td>\n",
       "      <td>5505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83585 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc_position  rel_score  ranking  query  score  binary_score\n",
       "cord_uid                                                              \n",
       "000ajevz          7623   0.004281    52295    NaN    NaN           NaN\n",
       "000q5l5n         17269   0.000000    77541    NaN    NaN           NaN\n",
       "000tfenb         66091   0.006773    38919    NaN    NaN           NaN\n",
       "001u8ecb          6127   0.026825     3817    NaN    NaN           NaN\n",
       "003r4sjl         24650   0.002933    60799    NaN    NaN           NaN\n",
       "...                ...        ...      ...    ...    ...           ...\n",
       "zzvmj5qy         16372   0.006473    40313    NaN    NaN           NaN\n",
       "zzw7zlh6         12233   0.000788    74181    NaN    NaN           NaN\n",
       "zzxjv666         57978   0.011381    22277    NaN    NaN           NaN\n",
       "zzykyblm         75960   0.007800    34410    NaN    NaN           NaN\n",
       "zzys31e9         38250   0.023491     5505    NaN    NaN           NaN\n",
       "\n",
       "[83585 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics = results.set_index(\"cord_uid\").join(judgements_parcial.set_index(\"cord_uid\"))\n",
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we observe that there are null values. These null values mean that there are some documents of our corpus that are not relevance judged. \n",
    "\n",
    "At this point have two possible options:\n",
    "* Drop the null values: since those documents are not judged, we don´t know whether they are relevant or not for that query. It makes sense to us dropping those documents, since assuming that they are relevant or not introduces uncertainty in our model.\n",
    "* Mark them as non-relevant: after reading the TREC guide for evaluation, we understood how this relevance judgements files are created by means of pools. It is indicated that documents not included in the pool should be marked as non-relevant. However, it´s also said that this approach is a bit controversial. \n",
    "\n",
    "After some more research, we realized that this is one of the most controversial aspects on evaluating information retrieval systems. Finally, we opted for the first action, since it made more sense for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:24.535299Z",
     "start_time": "2020-12-13T09:24:24.518299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_position</th>\n",
       "      <th>rel_score</th>\n",
       "      <th>ranking</th>\n",
       "      <th>query</th>\n",
       "      <th>score</th>\n",
       "      <th>binary_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cord_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01goni72</th>\n",
       "      <td>9241</td>\n",
       "      <td>0.031456</td>\n",
       "      <td>2397</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01yc7lzk</th>\n",
       "      <td>47554</td>\n",
       "      <td>0.052520</td>\n",
       "      <td>408</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01yc7lzk</th>\n",
       "      <td>1294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75891</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03id5o2g</th>\n",
       "      <td>3289</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>9643</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03id5o2g</th>\n",
       "      <td>15835</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>48305</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zvngy7zz</th>\n",
       "      <td>47713</td>\n",
       "      <td>0.050793</td>\n",
       "      <td>462</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zvvwwc0r</th>\n",
       "      <td>27644</td>\n",
       "      <td>0.049317</td>\n",
       "      <td>506</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zx28gr34</th>\n",
       "      <td>77614</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>63194</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxx7tikz</th>\n",
       "      <td>67893</td>\n",
       "      <td>0.017106</td>\n",
       "      <td>11299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zytu7wue</th>\n",
       "      <td>11842</td>\n",
       "      <td>0.100053</td>\n",
       "      <td>66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1064 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc_position  rel_score  ranking  query  score  binary_score\n",
       "cord_uid                                                              \n",
       "01goni72          9241   0.031456     2397    2.0    2.0           1.0\n",
       "01yc7lzk         47554   0.052520      408    2.0    0.0           0.0\n",
       "01yc7lzk          1294   0.000000    75891    2.0    0.0           0.0\n",
       "03id5o2g          3289   0.018495     9643    2.0    0.0           0.0\n",
       "03id5o2g         15835   0.004957    48305    2.0    0.0           0.0\n",
       "...                ...        ...      ...    ...    ...           ...\n",
       "zvngy7zz         47713   0.050793      462    2.0    2.0           1.0\n",
       "zvvwwc0r         27644   0.049317      506    2.0    2.0           1.0\n",
       "zx28gr34         77614   0.002560    63194    2.0    0.0           0.0\n",
       "zxx7tikz         67893   0.017106    11299    2.0    2.0           1.0\n",
       "zytu7wue         11842   0.100053       66    2.0    0.0           0.0\n",
       "\n",
       "[1064 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop values\n",
    "statistics = statistics.dropna()\n",
    "# Mark them as non relevant\n",
    "#a[\"binary_score\"].fillna(0, inplace=True)\n",
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we already know whether each retrieved document is relevant or not.\n",
    "\n",
    "Now, we compute the total number of relevant documents, it will be used later.\n",
    "\n",
    "And, we remove all the results whose computed tfidf score is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:26.162373Z",
     "start_time": "2020-12-13T09:24:26.159372Z"
    }
   },
   "outputs": [],
   "source": [
    "r = statistics[\"binary_score\"].sum()\n",
    "statistics = statistics[statistics[\"rel_score\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:27.286628Z",
     "start_time": "2020-12-13T09:24:27.273628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_position</th>\n",
       "      <th>rel_score</th>\n",
       "      <th>ranking</th>\n",
       "      <th>query</th>\n",
       "      <th>score</th>\n",
       "      <th>binary_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cord_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01goni72</th>\n",
       "      <td>9241</td>\n",
       "      <td>0.031456</td>\n",
       "      <td>2397</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01yc7lzk</th>\n",
       "      <td>47554</td>\n",
       "      <td>0.052520</td>\n",
       "      <td>408</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03id5o2g</th>\n",
       "      <td>3289</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>9643</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03id5o2g</th>\n",
       "      <td>15835</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>48305</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03s9spbi</th>\n",
       "      <td>330</td>\n",
       "      <td>0.179369</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zvngy7zz</th>\n",
       "      <td>47713</td>\n",
       "      <td>0.050793</td>\n",
       "      <td>462</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zvvwwc0r</th>\n",
       "      <td>27644</td>\n",
       "      <td>0.049317</td>\n",
       "      <td>506</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zx28gr34</th>\n",
       "      <td>77614</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>63194</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxx7tikz</th>\n",
       "      <td>67893</td>\n",
       "      <td>0.017106</td>\n",
       "      <td>11299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zytu7wue</th>\n",
       "      <td>11842</td>\n",
       "      <td>0.100053</td>\n",
       "      <td>66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1038 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc_position  rel_score  ranking  query  score  binary_score\n",
       "cord_uid                                                              \n",
       "01goni72          9241   0.031456     2397    2.0    2.0           1.0\n",
       "01yc7lzk         47554   0.052520      408    2.0    0.0           0.0\n",
       "03id5o2g          3289   0.018495     9643    2.0    0.0           0.0\n",
       "03id5o2g         15835   0.004957    48305    2.0    0.0           0.0\n",
       "03s9spbi           330   0.179369       27    2.0    2.0           1.0\n",
       "...                ...        ...      ...    ...    ...           ...\n",
       "zvngy7zz         47713   0.050793      462    2.0    2.0           1.0\n",
       "zvvwwc0r         27644   0.049317      506    2.0    2.0           1.0\n",
       "zx28gr34         77614   0.002560    63194    2.0    0.0           0.0\n",
       "zxx7tikz         67893   0.017106    11299    2.0    2.0           1.0\n",
       "zytu7wue         11842   0.100053       66    2.0    0.0           0.0\n",
       "\n",
       "[1038 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We order our statistics by the ranking and reset the index.\n",
    "\n",
    "We compute the actual rank (starting in 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:28.917275Z",
     "start_time": "2020-12-13T09:24:28.910276Z"
    }
   },
   "outputs": [],
   "source": [
    "statistics = statistics.sort_values(by=[\"ranking\"])\n",
    "statistics = statistics.reset_index()\n",
    "statistics[\"rank\"] = statistics.index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T17:05:40.594445Z",
     "start_time": "2020-12-07T17:05:40.591445Z"
    }
   },
   "source": [
    "Now, we compute precision and recall for each position of the ranking. Notice that we are making the table explained in the lecture notes (slide 51)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:38.254464Z",
     "start_time": "2020-12-13T09:24:38.248464Z"
    }
   },
   "outputs": [],
   "source": [
    "statistics[\"relevant\"] = statistics[\"binary_score\"]\n",
    "statistics[\"rel_retrieved\"] = statistics[\"binary_score\"].cumsum()\n",
    "statistics[\"precision\"] = statistics[\"rel_retrieved\"] / statistics[\"rank\"]\n",
    "statistics[\"recall\"] = statistics[\"rel_retrieved\"] / r\n",
    "statistics.drop([\"doc_position\", \"score\", \"binary_score\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:39.214121Z",
     "start_time": "2020-12-13T09:24:39.200124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>rel_score</th>\n",
       "      <th>ranking</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>rel_retrieved</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kftchnhz</td>\n",
       "      <td>0.420703</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2p9j4ksy</td>\n",
       "      <td>0.387222</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>akb96git</td>\n",
       "      <td>0.348274</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.004255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h5ufxzv9</td>\n",
       "      <td>0.323658</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.004255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lv8dvdp7</td>\n",
       "      <td>0.292001</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.004255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>wr2sgixs</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>74822</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.222437</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>uxnxsdtw</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>74998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>fvj3cpie</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>75060</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.222008</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>xhffsa77</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>75198</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.221794</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>3xq5jwof</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>75438</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.221580</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1038 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid  rel_score  ranking  query  rank  relevant  rel_retrieved  \\\n",
       "0     kftchnhz   0.420703        0    2.0     1       0.0            0.0   \n",
       "1     2p9j4ksy   0.387222        1    2.0     2       0.0            0.0   \n",
       "2     akb96git   0.348274        2    2.0     3       1.0            1.0   \n",
       "3     h5ufxzv9   0.323658        3    2.0     4       0.0            1.0   \n",
       "4     lv8dvdp7   0.292001        4    2.0     5       0.0            1.0   \n",
       "...        ...        ...      ...    ...   ...       ...            ...   \n",
       "1033  wr2sgixs   0.000660    74822    2.0  1034       0.0          230.0   \n",
       "1034  uxnxsdtw   0.000621    74998    2.0  1035       0.0          230.0   \n",
       "1035  fvj3cpie   0.000606    75060    2.0  1036       0.0          230.0   \n",
       "1036  xhffsa77   0.000573    75198    2.0  1037       0.0          230.0   \n",
       "1037  3xq5jwof   0.000502    75438    2.0  1038       0.0          230.0   \n",
       "\n",
       "      precision    recall  \n",
       "0      0.000000  0.000000  \n",
       "1      0.000000  0.000000  \n",
       "2      0.333333  0.004255  \n",
       "3      0.250000  0.004255  \n",
       "4      0.200000  0.004255  \n",
       "...         ...       ...  \n",
       "1033   0.222437  0.978723  \n",
       "1034   0.222222  0.978723  \n",
       "1035   0.222008  0.978723  \n",
       "1036   0.221794  0.978723  \n",
       "1037   0.221580  0.978723  \n",
       "\n",
       "[1038 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compute the Mean Average Precision, the P@5 and P@10 and the R-Precision.\n",
    "\n",
    "This metrics and the precision and recall will be very helpfull for the evaluation of our models.\n",
    "\n",
    "* **Precision** = relevant documents retrieved / documents retrieved. \n",
    "* **Recall** = relevant documents retrieved / total amount of relevant documents\n",
    "* **P@X**: precision at position X of our ranking\n",
    "* **R-Precision**: precision at position R of our ranking, being R the total number of relevant documents for that query (remember that before we computed some r? That r is this R.)\n",
    "* **Mean Average Precision**: average of precisions after some relevant document is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:40.860889Z",
     "start_time": "2020-12-13T09:24:40.855888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean average precision of TFIDF model for query 2 ==> 0.3546988024393504\n",
      "R-precision of TFIDF model for query 2 ==> 0.4\n",
      "P@5 of this model for query 2 ==> 0.2\n",
      "P@10 of this model for query 2 ==> 0.4\n"
     ]
    }
   ],
   "source": [
    "mavp = (statistics[\"precision\"] * statistics[\"relevant\"]).sum() / r\n",
    "r_precision = statistics.iloc[int(r-1)].precision\n",
    "p_5 = statistics.iloc[4].precision\n",
    "p_10 = statistics.iloc[9].precision\n",
    "\n",
    "print(f\"Mean average precision of TFIDF model for query 2 ==> {mavp}\")\n",
    "print(f\"R-precision of TFIDF model for query 2 ==> {r_precision}\")\n",
    "print(f\"P@5 of this model for query 2 ==> {p_5}\")\n",
    "print(f\"P@10 of this model for query 2 ==> {p_10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the precision vs recall figure, but using the standarized metric as explained in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:43.621884Z",
     "start_time": "2020-12-13T09:24:43.618882Z"
    }
   },
   "outputs": [],
   "source": [
    "precision = statistics[\"precision\"].values\n",
    "recall = statistics[\"recall\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:44.348873Z",
     "start_time": "2020-12-13T09:24:44.344871Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_higher_precision(statistics, recall):\n",
    "    \"\"\"\n",
    "    Auxiliary function to obtain the higher precision for a given recall value.\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        index = statistics.index[statistics['recall'] >= recall].tolist()[0] \n",
    "        return statistics.iloc[index:][\"precision\"].max()\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:44.923665Z",
     "start_time": "2020-12-13T09:24:44.916664Z"
    }
   },
   "outputs": [],
   "source": [
    "precision_recall = [[recall_i, get_higher_precision(statistics, recall_i)] for recall_i in np.arange(0,recall.max()+0.1, 0.1)]\n",
    "precision = [precision[1] for precision in precision_recall]\n",
    "recall = [recall[0] for recall in precision_recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:45.869426Z",
     "start_time": "2020-12-13T09:24:45.753425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"Precision vs recall standardized\")\n",
    "plt.plot(recall, precision, \"r-o\")\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterized Evaluation\n",
    "\n",
    "Before, we have explained step by step how the statistics are computed.\n",
    "\n",
    "The following three cells have the same code as above, but in functions so as to be reused later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:47.884861Z",
     "start_time": "2020-12-13T09:24:47.881862Z"
    }
   },
   "outputs": [],
   "source": [
    "def launch(function, model,dictionary,bow,index,titles):\n",
    "    \"\"\"\n",
    "    God function that allow us to pass independent launch query functions to our get_statistics function. \n",
    "    For more info, check Currying (Functional Programming).\n",
    "    \n",
    "    \"\"\"\n",
    "    def h(query):\n",
    "        return function(model,dictionary,bow,index,query,titles)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:50.694671Z",
     "start_time": "2020-12-13T09:24:50.689672Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_statistics(launch_query, queries, titles, metadata, judgements):\n",
    "    \"\"\"\n",
    "    General function that allow us to get statistics for all queries given a specific launch query function (model).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    It returns all the metrics explained before.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for index in range(len(queries)):\n",
    "        ranking, _ = launch_query(queries.iloc[index][0])#\n",
    "        result = get_statistics_query(ranking, index+1, titles, metadata, judgements)\n",
    "        results.append(result)\n",
    "    mavp = np.array([query[\"mavp\"] for query in results]).mean()\n",
    "    precision = np.array([query[\"precision\"] for query in results]).mean(axis=0)\n",
    "    r_precision = [query[\"r-precision\"] for query in results]\n",
    "    p_5 = [query[\"p_5\"] for query in results]\n",
    "    p_10 = [query[\"p_10\"] for query in results]\n",
    "    recall = np.array([query[\"recall\"] for query in results]).mean(axis=0)\n",
    "    return {\"mavp\": mavp, \"precision\":precision, \"r-precision\":r_precision, \"recall\":recall, \"p_5\": p_5, \"p_10\": p_10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:24:51.778668Z",
     "start_time": "2020-12-13T09:24:51.765671Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_statistics_query(ranking, id_query, titles, metadata, judgements):\n",
    "    \"\"\"\n",
    "    Individual function to compute the statistics for a specific query.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    It returns all the metrics explained before.\n",
    "    \"\"\"\n",
    "    ranking = [[position[0], position[1]] for position in ranking]\n",
    "    ranking = pd.DataFrame(ranking, columns=[\"doc_position\", \"rel_score\"])\n",
    "    results = ranking\n",
    "    results[\"sha\"] = results[\"doc_position\"].map(lambda x: titles[\"id\"].iloc[x])\n",
    "    results[\"ranking\"] = results.index\n",
    "    results = results.set_index(\"sha\").join(metadata.set_index(\"sha\"))\n",
    "    results = results.sort_values(by=[\"ranking\"])\n",
    "    results = results.dropna()\n",
    "    judgements_parcial = judgements[judgements[\"query\"] == id_query]\n",
    "    statistics = results.set_index(\"cord_uid\").join(judgements_parcial.set_index(\"cord_uid\"))\n",
    "    statistics = statistics.dropna()\n",
    "    r = statistics[\"binary_score\"].sum()\n",
    "    statistics = statistics[statistics[\"rel_score\"]>0]\n",
    "    statistics = statistics.sort_values(by=[\"ranking\"])\n",
    "    statistics = statistics.reset_index()\n",
    "    statistics[\"rank\"] = statistics.index+1\n",
    "    statistics[\"relevant\"] = statistics[\"binary_score\"]\n",
    "    statistics[\"rel_retrieved\"] = statistics[\"binary_score\"].cumsum()\n",
    "    statistics[\"precision\"] = statistics[\"rel_retrieved\"] / statistics[\"rank\"]\n",
    "    r = statistics[\"relevant\"].sum()\n",
    "    if r == 0:\n",
    "        return {\"mavp\": 0, \"r-precision\": 0, \"precision\": list(np.zeros(11)), \"recall\":0, \"p_10\": 0, \"p_5\": 0}\n",
    "    statistics[\"recall\"] = statistics[\"rel_retrieved\"] / r\n",
    "    statistics.drop([\"doc_position\", \"score\", \"binary_score\"], axis=1, inplace=True)\n",
    "    mavp = (statistics[\"precision\"] * statistics[\"relevant\"]).sum() / r\n",
    "    r_precision = statistics.iloc[int(r-1)].precision\n",
    "    precision = statistics[\"precision\"].values\n",
    "    recall = statistics[\"recall\"].values\n",
    "    recall_range = np.arange(0,recall.max()+0.1, 0.1)\n",
    "    precision_recall = [[recall, get_higher_precision(statistics, recall)] for recall in recall_range]\n",
    "    precision = [precision[1] for precision in precision_recall]\n",
    "    p_5 = statistics.iloc[4].precision\n",
    "    p_10 = statistics.iloc[9].precision\n",
    "    return {\"mavp\": mavp, \"r-precision\": r_precision, \"precision\": precision, \"recall\":recall_range, \"p_10\": p_10, \"p_5\":p_5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF 2.0\n",
    "\n",
    "Once we have all our structure created: launching queries and computing statistics, we create 4 variations of the TFIDF Model playing with the SMART notation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:33:06.801631Z",
     "start_time": "2020-12-13T09:24:57.151018Z"
    }
   },
   "outputs": [],
   "source": [
    "model_tfidf_3 = models.TfidfModel(bow, smartirs=\"lpu\") # Logarithmic term frequency weighting, probabilistic document frequency weighting \n",
    "                                                        # and pivoted unique normalization\n",
    "model_tfidf_2 = models.TfidfModel(bow, smartirs=\"lfc\") # Logarithmic term frequency weighting, idf document frequency weighting \n",
    "                                                         # and cosine normalization\n",
    "model_tfidf_5 = models.TfidfModel(bow, smartirs=\"ltc\") # Logarithmic term frequency weighting, zero-corrected idf document frequency weighting \n",
    "                                                         # and cosine normalization\n",
    "model_tfidf_4 = models.TfidfModel(bow, smartirs=\"nnn\") # Raw term frequency weighting, none document frequency weighting \n",
    "                                                         # and none normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "After creating several TFIDF models, we wanted to try the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T10:25:01.891410Z",
     "start_time": "2020-12-13T10:25:01.885411Z"
    }
   },
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\&)|(\\%)|(\\$)|(\\€)|(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)|(\\⁰)|(\\•)|(\\\\')\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def clean(doc):\n",
    "    \"\"\"\n",
    "    Basic function to clean a document being a document a string with words separated by blank spaces.\n",
    "    \"\"\"\n",
    "    doc = REPLACE_NO_SPACE.sub(NO_SPACE, doc.lower())\n",
    "    doc = REPLACE_WITH_SPACE.sub(SPACE, doc)\n",
    "    stopset = set(stopwords.words(\"english\"))\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = wordpunct_tokenize(doc)\n",
    "    clean = [token.lower() for token in tokens if token not in stopset and len(token) > 2 and not token.isnumeric()]\n",
    "    final = [stemmer.stem(token) for token in clean]\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation\n",
    "\n",
    "The first thing that we need to do is to create our Word2Vec model. To do that, we need to obtain our dataset (documents and queries).\n",
    "\n",
    "The following cells create the dataset for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T10:25:17.476303Z",
     "start_time": "2020-12-13T10:25:12.366765Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = pd.DataFrame((line for line in open(\"docs.txt\")), columns = [\"preprocess\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T10:25:18.330304Z",
     "start_time": "2020-12-13T10:25:18.312305Z"
    }
   },
   "outputs": [],
   "source": [
    "queries_w2v = queries.copy()\n",
    "queries_w2v[\"preprocess\"] = queries_w2v[\"query\"].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T10:25:25.049328Z",
     "start_time": "2020-12-13T10:25:25.008315Z"
    }
   },
   "outputs": [],
   "source": [
    "combined = pd.concat((docs[\"preprocess\"], queries_w2v[\"preprocess\"])).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our dataset, it´s time to create and train our model. \n",
    "* **Size**: this is the size of the word embeddings. We chose this value after looking in some papers that suggested using a size between 200-500 for large corpus (as ours).\n",
    "* **Workers**: if you execute this code, please change this number to maximum number of threads of your computer (cores x 2 if you have hyper threading)\n",
    "\n",
    "**IMPORTANT** The following cell takes 10 minutes to finish in a computer with a Ryzen 5 3600. Remember this before executing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:36.286Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model = models.Word2Vec([i.split() for i in combined], size = 300, workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:36.928Z"
    }
   },
   "outputs": [],
   "source": [
    "len(w2v_model.wv.vocab) # We check the size of our vocabulary, having more than 300k unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving\n",
    "\n",
    "After creating our model, we can save it for later use in other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:40.767Z"
    }
   },
   "outputs": [],
   "source": [
    "word_vectors = w2v_model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:42.214Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:42.655Z"
    }
   },
   "outputs": [],
   "source": [
    "del w2v_model # We delete the model since we only need the word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading\n",
    "\n",
    "We load our word_vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:43.783Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:46.385Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embedding_w2v(doc_tokens):\n",
    "    \"\"\"\n",
    "    Basic function to obtain the vector representation of a given document (list of tokens).\n",
    "    \n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    if len(doc_tokens) < 1: # If the length of our document is 0 we return a vector of zeros with size 300 (remember this is the vector size used when creating the model)\n",
    "        return np.zeros(300)\n",
    "    else:\n",
    "        for token in doc_tokens:\n",
    "            if token in word_vectors.vocab: # if the word is in our vocabulary, we get its vector\n",
    "                embeddings.append(word_vectors.word_vec(token))\n",
    "            else:\n",
    "                embeddings.append(np.random.rand(300)) # if it´s not in our vocabulary a random vector is used\n",
    "        return np.mean(embeddings, axis = 0) # the vector representation of a document is the mean of its word´s vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries embeddings\n",
    "\n",
    "We compute the vector representations of our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:50.600Z"
    }
   },
   "outputs": [],
   "source": [
    "queries_w2v[\"embeddings\"] = queries_w2v[\"preprocess\"].apply(lambda x: get_embedding_w2v(x.split()))\n",
    "queries_w2v.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce the amount of embeddings to be computed, we filter the documents and we only save the ones that have some query performed on it and appear in metadata.\n",
    "Then, we compute the embedding for each document, so as to have it precomputed and then, when computing the similarity, just taking this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:52.832Z"
    }
   },
   "outputs": [],
   "source": [
    "titles_w2v = titles.copy()\n",
    "titles_w2v = titles_w2v.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:53.392Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = titles_w2v.join(docs)\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:53.984Z"
    }
   },
   "outputs": [],
   "source": [
    "# With this filter, we only use documents that appear in both judgements and metadata files, i.e, documents that have queries related.\n",
    "docs[\"sha\"] = docs[\"id\"]\n",
    "inCorpus = metadata[metadata[\"sha\"].isin(docs[\"sha\"])][\"cord_uid\"]\n",
    "inJudgements = inCorpus[inCorpus.isin(judgements[\"cord_uid\"])]\n",
    "filtered = metadata.loc[metadata['cord_uid'].isin(inJudgements)][\"sha\"].values\n",
    "docs_filtered = docs.loc[docs[\"id\"].isin(filtered)]\n",
    "docs_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:54.712Z"
    }
   },
   "outputs": [],
   "source": [
    "docs_filtered[\"embeddings\"] = docs_filtered[\"preprocess\"].apply(lambda x: get_embedding_w2v(x.split())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:55.264Z"
    }
   },
   "outputs": [],
   "source": [
    "docs_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch query in W2V Model\n",
    "\n",
    "As before with the TFIDF model, we create two functions to launch queries with our W2V model.\n",
    "\n",
    "We will show you the results for query 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:57.064Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "i = 2\n",
    "\n",
    "def launch_query_w2v(query_name, queries, docs_filtered, verbose=0):\n",
    "    \"\"\"\n",
    "    General function that allow us to launch queries to our W2V model.\n",
    "    \n",
    "    Parameter:\n",
    "    query_name: the name of the query\n",
    "    queries: dataframe of the queries\n",
    "    docs_filtered: dataframe of filtered documents with their vector representation (the one explained before)\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    It returns the ranking.\n",
    "    \n",
    "    \"\"\"\n",
    "    query_name = query_name\n",
    "    # We obtain the vector of the query\n",
    "    query_vector = queries[queries[\"query\"] == query_name][\"embeddings\"].values[0]\n",
    "    docs_aux = docs_filtered.copy()\n",
    "    # We compute the cosine similarity of the query´s vector with the documents vectors\n",
    "    docs_aux[\"score\"] = docs_aux[\"embeddings\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_vector).reshape(1,-1), np.array(x).reshape(1,-1)).item())\n",
    "    # We order the docs by this similarity\n",
    "    docs_aux = docs_aux.sort_values(by=\"score\", ascending=False)\n",
    "    doc_pos = docs_aux.index.values\n",
    "    rel_score = docs_aux[\"score\"].values\n",
    "    ranking = [z for z in zip(doc_pos, rel_score)]\n",
    "    if verbose:\n",
    "        print(\"Query ==> \"+query_name)\n",
    "        for i in range(5):\n",
    "            score = docs_aux.iloc[i][\"score\"]\n",
    "            title = docs_aux.iloc[i][\"title\"] if docs_aux.iloc[i][\"title\"]!=\"\" else \"No title available\"\n",
    "            print(f\"[Score = {score}] \"+ title)\n",
    "    return ranking, \"Just to work\"\n",
    "\n",
    "def launch_w2v(function, queries, docs_filtered):\n",
    "    \"\"\"\n",
    "    Again, function that allow us to reuse our code for evaluation.\n",
    "    \"\"\"\n",
    "    def h(query_name):\n",
    "        return function(query_name, queries, docs_filtered)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution of query 2 with its results. Notice that now the scores are higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:26:58.585Z"
    }
   },
   "outputs": [],
   "source": [
    "ranking, _ = launch_query_w2v(queries_w2v.iloc[1][0], queries_w2v, docs_filtered, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSI (Deerwester et al., 1990) is a retrieval model based on distributional semantics, that assumes that words tend to have similar meanings if they are used in the same context. This model uses Singular Value Decomposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we first create the model. To do that, we need to compute the corpus in tfidf format. Once it´s done, we create the model using 100 as number of topics. The related literature suggested using a num_topics from hundreds to thousand, so we chose 100 since for this value we already obtain good performance and the execution time isn´t too big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** The following cell takes 5 minutes more or less to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:52:27.057197Z",
     "start_time": "2020-12-13T09:41:04.598518Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = model_tfidf[bow]\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics = 100)\n",
    "lsi.save(\"model_lsi.lsi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:59:54.057586Z",
     "start_time": "2020-12-13T09:52:27.314199Z"
    }
   },
   "outputs": [],
   "source": [
    "index_lsi = Similarity(None, lsi[corpus_tfidf], num_features=len(dictionary))\n",
    "index_lsi.save(\"covid19-lsi.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the code needed to launch a query with LSI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:59:54.314589Z",
     "start_time": "2020-12-13T09:59:54.310586Z"
    }
   },
   "outputs": [],
   "source": [
    "def launch_query_lsi(model, dictionary, bow, index, query, titles, verbose = 0):\n",
    "    \"\"\"\n",
    "    Given a specific query, it returns the ranking of documents.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : tfidf model\n",
    "    dictionary: dictionary created\n",
    "    bow: bag of words\n",
    "    index: similarities matrix\n",
    "    query: specific query\n",
    "    titles: dataframe of the titles\n",
    "    verbose: flag for printing messages\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ranking: ranking for the query in this format: [(doc_position, score), (doc_position, score), ... ]\n",
    "    similarities: similarities matrix\n",
    "\n",
    "    \"\"\"\n",
    "    stopset = set(stopwords.words(\"english\"))\n",
    "    index = index\n",
    "    pq = preprocess_query_tfidf(query, stopset)\n",
    "    vq = dictionary.doc2bow(pq)\n",
    "    veclsi = model[model_tfidf[vq]]\n",
    "    sim = index[veclsi]\n",
    "    ranking = sorted(enumerate(sim), key=itemgetter(1), reverse=True)\n",
    "    if verbose:\n",
    "        print(\"Query ==> \"+query)\n",
    "        for doc, score in ranking[:5]:\n",
    "            print(\"[ Score = \" + \"%.3f\" % round(score,3) + \" ] \" + titles['title'].iloc[doc])\n",
    "    return ranking, sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launching query *origin coronavirus*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T09:59:54.683587Z",
     "start_time": "2020-12-13T09:59:54.572587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ==> origin coronavirus\n",
      "[ Score = 0.781 ] Classical Coronaviruses-nCoV · MERS-CoV · SARS-CoV · Strain 229E · Strain OC43 · Coronavirus\n",
      "[ Score = 0.740 ] COVID-19: Zoonotic aspects Fig. 1. Potential transmission cycles of SARS-CoV2 (formerly 2019nCoV). Travel Medicine and Infectious Disease xxx (xxxx) xxxx\n",
      "[ Score = 0.722 ] Analyzing the epidemiological outbreak of COVID-19: A visual exploratory data analysis approach\n",
      "[ Score = 0.713 ] The global emergence of severe acute respiratory syndrome coronavirus 2 in human\n",
      "[ Score = 0.709 ] Journal Pre-proof Recent progress and challenges in drug development against COVID-19 coronavirus (SARS-CoV-2) -an update on the status Recent progress and challenges in drug development against COVID-19 Coronavirus (SARS-CoV-2) -an update on the status\n"
     ]
    }
   ],
   "source": [
    "ranking, _ = launch_query_lsi(lsi, dictionary, bow, index_lsi, \"origin coronavirus\", titles, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "So, after explaining how we implemented the models, it´s turn to evaluate them.\n",
    "\n",
    "We will consider the metrics explained before: precision, recall, mean average precision, P@5, P@10 and R-Precision.\n",
    "\n",
    "The following cell performs all the evaluation:\n",
    "* We print the P@5, P@10 and MAVP of each single document.\n",
    "* We plot a graph comparing the precision and recall of all the models tested.\n",
    "* We plot a graph comparing the difference of the R-precision of the best two models for each single query. If the values are positive mean that R-precision of model A was greater than model´s B R-Precision. Negative values mean that that R-precision of model B was greater than model´s A R-Precision\n",
    "\n",
    "The evaluation procedure was created following the indications in (Baeza and Ribeiro, 2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-13T10:27:03.137Z"
    }
   },
   "outputs": [],
   "source": [
    "recall = np.arange(0,1.1, 0.1)\n",
    "modelos_tfidf = [{\"name\":\"TFIDF (nfc)\", \"term\": \"raw\", \"document\": \"idf\", \"normalization\": \"cosine\", \"model\": model_tfidf, \"color\": \"r\"},\n",
    "          {\"name\":\"TFIDF (lfc)\", \"term\": \"logarithmic\", \"document\": \"idf\", \"normalization\": \"cosine\", \n",
    "           \"model\": model_tfidf_2, \"color\": \"g\"},\n",
    "           {\"name\":\"TFIDF (lpu)\", \"term\": \"logarithmic\", \"document\": \"probabilistic\", \"normalization\": \"pivoted unique\", \n",
    "           \"model\": model_tfidf_3, \"color\": \"b\"},\n",
    "           {\"name\":\"TFIDF (nnn)\", \"term\": \"raw\", \"document\": \"none\", \"normalization\": \"none\", \n",
    "           \"model\": model_tfidf_4, \"color\": \"c\"},\n",
    "           {\"name\":\"TFIDF (ltc)\", \"term\": \"logarithmic\", \"document\": \"zero-corrected idf\", \"normalization\": \"cosine\", \n",
    "           \"model\": model_tfidf_5, \"color\": \"m\"}\n",
    "         ]\n",
    "\n",
    "modelos_w2v = [{\"name\": \"Word2Vec\", \"algorithm\": \"Continuous Bag of Words\", \"vector\": 300, \n",
    "                \"window\": \"5 (default)\", \"negative\": \"5 (default)\", \"epochs\": \"5 (default)\", \"color\":\"y\"}\n",
    "              ]\n",
    "\n",
    "modelos_lsi = [{\"name\": \"Latent Semantic Index\", \"vector\": 100, \"version\": \"tfidf\", \"color\":\"k\", \"model\": lsi}]\n",
    "               \n",
    "r_precisions = []\n",
    "precisions_5 = []\n",
    "precisions_10 = []\n",
    "\n",
    "print(\"###################################################################################\")\n",
    "print(\"Evaluating performance of our models...\")\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Precision vs Recall standardized\")\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "\n",
    "for model in modelos_tfidf:\n",
    "    name = model[\"name\"]\n",
    "    term = model[\"term\"]\n",
    "    document = model[\"document\"]\n",
    "    normalization = model[\"normalization\"]\n",
    "    color = model[\"color\"]\n",
    "    print(\"-------------------------------------------------------------------------------------\")\n",
    "    print(f\"Evaluating {name}: {term} term frequency weighing, {document} document frequency weighting, {normalization} normalization\")\n",
    "    print(\"Computing statistics...\")\n",
    "    data_tfidf = get_statistics(launch(launch_query_tfidf,model[\"model\"], dictionary, bow, similarities, titles.copy()), queries.copy(), titles.copy(), metadata.copy(), judgements.copy())\n",
    "    print(\"Statistics computed...\")\n",
    "    precision_tfidf = data_tfidf[\"precision\"]\n",
    "    recall = data_tfidf[\"recall\"]\n",
    "    mavp_tfidf = data_tfidf[\"mavp\"]\n",
    "    precisions_5.append(np.array(data_tfidf[\"p_5\"]).mean())\n",
    "    precisions_10.append(np.array(data_tfidf[\"p_10\"]).mean())\n",
    "    r_precisions.append(data_tfidf[\"r-precision\"])\n",
    "    print(f\"Mean Average Precision of this model ==> {mavp_tfidf}\")\n",
    "    p_5 = np.array(data_tfidf[\"p_5\"]).mean()\n",
    "    p_10 = np.array(data_tfidf[\"p_10\"]).mean()\n",
    "    print(f\"Mean P@5 of this model ==> {p_5}\")\n",
    "    print(f\"Mean P@10 of this model ==> {p_10}\")\n",
    "\n",
    "    plt.plot(recall, precision_tfidf, f\"{color}-o\", label=name)\n",
    "\n",
    "for model in modelos_w2v:\n",
    "    name = model[\"name\"]\n",
    "    vector = model[\"vector\"]\n",
    "    window = model[\"window\"]\n",
    "    negative = model[\"negative\"]\n",
    "    algorithm = model[\"algorithm\"]\n",
    "    epochs = model[\"epochs\"]\n",
    "    color = model[\"color\"]\n",
    "    print(\"-------------------------------------------------------------------------------------\")\n",
    "    print(f\"Evaluating {name}: \\n\\tTraining algorithm = {algorithm}\\n\\tVector size = {vector}\\n\\tDistance predicted and current word = {window}\\n\\tNegative sampling = {negative}\\n\\tEpochs = {epochs}\")\n",
    "    print(\"Computing statistics...\")\n",
    "    data_w2v = get_statistics(launch_w2v(launch_query_w2v, queries_w2v.copy(), docs_filtered.copy()), queries_w2v.copy(), titles_w2v.copy(), metadata.copy(), judgements.copy())\n",
    "    print(\"Statistics computed...\")\n",
    "    precision_w2v = data_w2v[\"precision\"]\n",
    "    recall = data_w2v[\"recall\"]\n",
    "    mavp_w2v = data_w2v[\"mavp\"]\n",
    "    r_precisions.append(data_w2v[\"r-precision\"])\n",
    "    precisions_5.append(np.array(data_w2v[\"p_5\"]).mean())\n",
    "    precisions_10.append(np.array(data_w2v[\"p_10\"]).mean())\n",
    "    print(f\"Mean Average Precision of this model ==> {mavp_w2v}\")\n",
    "    p_5 = np.array(data_w2v[\"p_5\"]).mean()\n",
    "    p_10 = np.array(data_w2v[\"p_10\"]).mean()\n",
    "    print(f\"Mean P@5 of this model ==> {p_5}\")\n",
    "    print(f\"Mean P@10 of this model ==> {p_10}\")\n",
    "\n",
    "    plt.plot(recall, precision_w2v, f\"{color}-o\", label=name)\n",
    "               \n",
    "for model in modelos_lsi:\n",
    "    name = model[\"name\"]\n",
    "    vector = model[\"vector\"]\n",
    "    version = model[\"version\"]\n",
    "    color = model[\"color\"]\n",
    "    print(\"-------------------------------------------------------------------------------------\")\n",
    "    print(f\"Evaluating {name}: \\n\\tVector size = {vector}\\n\\tCorpus version = {version}\")\n",
    "    print(\"Computing statistics...\")\n",
    "    data_lsi = get_statistics(launch(launch_query_lsi,model[\"model\"], dictionary, model_tfidf[bow], index_lsi, titles.copy()), queries.copy(), titles.copy(), metadata.copy(), judgements.copy())\n",
    "    print(\"Statistics computed...\")\n",
    "    precision_lsi = data_lsi[\"precision\"]\n",
    "    recall = data_lsi[\"recall\"]\n",
    "    mavp_lsi = data_lsi[\"mavp\"]\n",
    "    r_precisions.append(data_lsi[\"r-precision\"])\n",
    "    precisions_5.append(np.array(data_lsi[\"p_5\"]).mean())\n",
    "    precisions_10.append(np.array(data_lsi[\"p_10\"]).mean())\n",
    "    print(f\"Mean Average Precision of this model ==> {mavp_lsi}\")\n",
    "    p_5 = np.array(data_lsi[\"p_5\"]).mean()\n",
    "    p_10 = np.array(data_lsi[\"p_10\"]).mean()\n",
    "    print(f\"Mean P@5 of this model ==> {p_5}\")\n",
    "    print(f\"Mean P@10 of this model ==> {p_10}\")\n",
    "\n",
    "    plt.plot(recall, precision_lsi, f\"{color}-o\", label=name)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Comparing our models: W2V vs LSI\")\n",
    "r_precision = np.array(r_precisions[-2]) - np.array(r_precisions[-1])\n",
    "# the histogram of the data\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(np.arange(1,51,1),r_precision)\n",
    "plt.xlabel('Query number')\n",
    "plt.ylabel('R-Precision W2V/LSI')\n",
    "plt.title('Comparison of R-Precisions')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Evalution finished.\")\n",
    "print(\"###################################################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T14:51:15.363156Z",
     "start_time": "2020-12-12T14:51:15.357158Z"
    }
   },
   "source": [
    "Baeza-Yates, R., & Ribeiro-Neto, B. (2011). Modern information retrieval: the concepts and technology behind search. Choice Reviews Online, 48(12), 48-6950-48–6950. https://doi.org/10.5860/choice.48-6950\n",
    "\n",
    "Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990). Indexing by latent semantic analysis. In Journal of the American Society for Information Science (Vol. 41, Issue 6). https://doi.org/10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9\n",
    "\n",
    "Mikolov, T., Sutskever, I., Chen, K., Corrado, G., & Dean, J. (2013). Distributed representations ofwords and phrases and their compositionality. Advances in Neural Information Processing Systems. http://arxiv.org/abs/1310.4546\n",
    "\n",
    "Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. In 1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings. http://ronan.collobert.com/senna/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "322.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
